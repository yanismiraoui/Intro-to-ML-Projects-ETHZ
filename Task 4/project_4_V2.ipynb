{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries are imported\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import Draw\n",
    "from zipfile import ZipFile\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "print('libraries are imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, bottleneck, train_encoder):\n",
    "        super().__init__()\n",
    "        self.train_encoder = train_encoder\n",
    "        self.input_size = input_size\n",
    "        self.bottleneck = bottleneck\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.input_size, 512),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, self.bottleneck)\n",
    "        )\n",
    "\n",
    "        if self.train_encoder:\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Linear(self.bottleneck, 64),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(64, 128),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(128, 256),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(256, 512),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(512, self.input_size),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        else:\n",
    "            self.encoder.add_module(\"ReLU_last\", torch.nn.ReLU())\n",
    "            self.encoder.add_module(\"final_fc\", torch.nn.Linear(self.output_size, 1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        if self.train_encoder:\n",
    "            x = self.decoder(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "outputs": [],
   "source": [
    "class HomoLumo(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.input_size = n_features\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            ae_model.encoder,\n",
    "            nn.Linear(self.input_size, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "outputs": [],
   "source": [
    "class trainData(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "class testData(Dataset):\n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "outputs": [],
   "source": [
    "def df_to_tensor(df):\n",
    "    return torch.from_numpy(df.values).float()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "bottleneck = 50\n",
    "lr_rate = 0.001\n",
    "batch_size_1 = 128\n",
    "batch_size_2 = 2\n",
    "num_epochs_1 = 20\n",
    "num_epochs_2 = 20\n",
    "num_epochs_3 = 100\n",
    "train_percentage = 0.8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "outputs": [],
   "source": [
    "# First, we read in the pretrain features and corresponding labels and convert them into a tensor\n",
    "\n",
    "df_pretrain = pd.read_csv('data/pretrain_features.csv').set_index('Id')\n",
    "X_pretrain = df_to_tensor(df_pretrain[df_pretrain.columns[1:]])\n",
    "labels_pretrain = pd.read_csv('data/pretrain_labels.csv').set_index('Id')\n",
    "y_pretrain = df_to_tensor(labels_pretrain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "outputs": [],
   "source": [
    "# the pretrain data is loaded into a dataloader to use\n",
    "\n",
    "data_pretrain = trainData(X_pretrain, y_pretrain)\n",
    "pretrain_loader = DataLoader(data_pretrain, batch_size=batch_size_1, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "outputs": [],
   "source": [
    "input_size = X_pretrain.shape[1]\n",
    "\n",
    "ae_model = Autoencoder(input_size, bottleneck, train_encoder=True)\n",
    "\n",
    "ae_loss_fct = nn.MSELoss()\n",
    "ae_optimizer = Adam(ae_model.parameters(), lr=lr_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 25.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 20 , loss: tensor(0.0425, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 25.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 / 20 , loss: tensor(0.0426, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 25.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 / 20 , loss: tensor(0.0427, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:16<00:00, 24.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 / 20 , loss: tensor(0.0432, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 25.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 / 20 , loss: tensor(0.0426, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:22<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 / 20 , loss: tensor(0.0438, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:21<00:00, 18.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 / 20 , loss: tensor(0.0456, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:24<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 / 20 , loss: tensor(0.0437, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:20<00:00, 19.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 / 20 , loss: tensor(0.0454, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:19<00:00, 19.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 / 20 , loss: tensor(0.0443, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:21<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 / 20 , loss: tensor(0.0447, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:18<00:00, 20.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 / 20 , loss: tensor(0.0442, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:16<00:00, 24.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 / 20 , loss: tensor(0.0450, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 25.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 / 20 , loss: tensor(0.0447, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:16<00:00, 23.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 / 20 , loss: tensor(0.0441, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 25.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 / 20 , loss: tensor(0.0449, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:16<00:00, 23.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 / 20 , loss: tensor(0.0439, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 25.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 / 20 , loss: tensor(0.0446, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 25.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 / 20 , loss: tensor(0.0440, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:14<00:00, 26.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 / 20 , loss: tensor(0.0454, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#data, target = next(iter(pretrain_loader))\n",
    "\n",
    "for epoch in range(num_epochs_1):\n",
    "    for (data, target) in tqdm(pretrain_loader):\n",
    "\n",
    "        ae_optimizer.zero_grad()\n",
    "        recon_data = ae_model(data)\n",
    "\n",
    "        ae_loss = ae_loss_fct(recon_data, data)\n",
    "        ae_loss.backward()\n",
    "        ae_optimizer.step()\n",
    "\n",
    "    print('epoch', epoch + 1, '/', num_epochs_1, \", loss:\", ae_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 49.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 20 , loss: tensor(0.7287, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 49.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 / 20 , loss: tensor(0.6928, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 50.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 / 20 , loss: tensor(0.3828, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 49.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 / 20 , loss: tensor(0.3309, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 48.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 / 20 , loss: tensor(0.2628, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 49.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 / 20 , loss: tensor(0.1968, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 50.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 / 20 , loss: tensor(0.1837, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 49.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 / 20 , loss: tensor(0.1343, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 50.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 / 20 , loss: tensor(0.1234, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 49.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 / 20 , loss: tensor(0.1035, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 49.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 / 20 , loss: tensor(0.0684, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 48.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 / 20 , loss: tensor(0.0559, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 48.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 / 20 , loss: tensor(0.0374, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 50.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 / 20 , loss: tensor(0.0294, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 50.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 / 20 , loss: tensor(0.0225, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 50.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 / 20 , loss: tensor(0.0159, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 51.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 / 20 , loss: tensor(0.0178, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 50.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 / 20 , loss: tensor(0.0133, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 50.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 / 20 , loss: tensor(0.0158, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 49.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 / 20 , loss: tensor(0.0122, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "le_model = HomoLumo(bottleneck)\n",
    "\n",
    "le_loss_fct = nn.MSELoss()\n",
    "le_optimizer = Adam(le_model.parameters(), lr=lr_rate)\n",
    "\n",
    "for epoch in range(num_epochs_2):\n",
    "    for (X, y) in tqdm(pretrain_loader):\n",
    "\n",
    "        le_optimizer.zero_grad()\n",
    "        y_pred = le_model(X)\n",
    "\n",
    "        le_loss = le_loss_fct(y_pred, y)\n",
    "        le_loss.backward()\n",
    "        le_optimizer.step()\n",
    "\n",
    "    print('epoch', epoch + 1, '/', num_epochs_2, \", loss:\", le_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "outputs": [],
   "source": [
    "df_train_features = pd.read_csv('data/train_features.csv').set_index('Id')\n",
    "X_train_features = df_to_tensor(df_train_features[df_train_features.columns[1:]])\n",
    "#X_train_encoded = ae_model.encoder(X_train_features)\n",
    "\n",
    "data_size = len(X_train_features)\n",
    "test_cut = int(train_percentage*data_size)\n",
    "\n",
    "X_train = X_train_features[:test_cut, :]\n",
    "X_test =  X_train_features[test_cut:, :]\n",
    "\n",
    "labels_train = pd.read_csv('data/train_labels.csv').set_index('Id')\n",
    "y_train_labels = df_to_tensor(labels_train)\n",
    "\n",
    "y_train = y_train_labels[:test_cut, :]\n",
    "y_test =  y_train_labels[test_cut:, :]\n",
    "\n",
    "data_train = trainData(X_train, y_train)\n",
    "data_test = trainData(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size_2, shuffle=True)\n",
    "test_loader = DataLoader(data_test, batch_size=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 100 , loss: tensor(15.4575, grad_fn=<MseLossBackward0>)\n",
      "epoch 2 / 100 , loss: tensor(8.9857, grad_fn=<MseLossBackward0>)\n",
      "epoch 3 / 100 , loss: tensor(2.4555, grad_fn=<MseLossBackward0>)\n",
      "epoch 4 / 100 , loss: tensor(0.4656, grad_fn=<MseLossBackward0>)\n",
      "epoch 5 / 100 , loss: tensor(1.4390, grad_fn=<MseLossBackward0>)\n",
      "epoch 6 / 100 , loss: tensor(0.3817, grad_fn=<MseLossBackward0>)\n",
      "epoch 7 / 100 , loss: tensor(1.8562, grad_fn=<MseLossBackward0>)\n",
      "epoch 8 / 100 , loss: tensor(0.1537, grad_fn=<MseLossBackward0>)\n",
      "epoch 9 / 100 , loss: tensor(0.3093, grad_fn=<MseLossBackward0>)\n",
      "epoch 10 / 100 , loss: tensor(0.2648, grad_fn=<MseLossBackward0>)\n",
      "epoch 11 / 100 , loss: tensor(0.1075, grad_fn=<MseLossBackward0>)\n",
      "epoch 12 / 100 , loss: tensor(0.1290, grad_fn=<MseLossBackward0>)\n",
      "epoch 13 / 100 , loss: tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "epoch 14 / 100 , loss: tensor(0.3685, grad_fn=<MseLossBackward0>)\n",
      "epoch 15 / 100 , loss: tensor(0.2923, grad_fn=<MseLossBackward0>)\n",
      "epoch 16 / 100 , loss: tensor(0.3138, grad_fn=<MseLossBackward0>)\n",
      "epoch 17 / 100 , loss: tensor(0.1825, grad_fn=<MseLossBackward0>)\n",
      "epoch 18 / 100 , loss: tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "epoch 19 / 100 , loss: tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch 20 / 100 , loss: tensor(0.5281, grad_fn=<MseLossBackward0>)\n",
      "epoch 21 / 100 , loss: tensor(0.1148, grad_fn=<MseLossBackward0>)\n",
      "epoch 22 / 100 , loss: tensor(0.1636, grad_fn=<MseLossBackward0>)\n",
      "epoch 23 / 100 , loss: tensor(0.4658, grad_fn=<MseLossBackward0>)\n",
      "epoch 24 / 100 , loss: tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "epoch 25 / 100 , loss: tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "epoch 26 / 100 , loss: tensor(0.0585, grad_fn=<MseLossBackward0>)\n",
      "epoch 27 / 100 , loss: tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "epoch 28 / 100 , loss: tensor(0.2336, grad_fn=<MseLossBackward0>)\n",
      "epoch 29 / 100 , loss: tensor(0.1628, grad_fn=<MseLossBackward0>)\n",
      "epoch 30 / 100 , loss: tensor(0.7046, grad_fn=<MseLossBackward0>)\n",
      "epoch 31 / 100 , loss: tensor(0.1982, grad_fn=<MseLossBackward0>)\n",
      "epoch 32 / 100 , loss: tensor(0.3636, grad_fn=<MseLossBackward0>)\n",
      "epoch 33 / 100 , loss: tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch 34 / 100 , loss: tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "epoch 35 / 100 , loss: tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch 36 / 100 , loss: tensor(0.1397, grad_fn=<MseLossBackward0>)\n",
      "epoch 37 / 100 , loss: tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch 38 / 100 , loss: tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch 39 / 100 , loss: tensor(0.1138, grad_fn=<MseLossBackward0>)\n",
      "epoch 40 / 100 , loss: tensor(0.2020, grad_fn=<MseLossBackward0>)\n",
      "epoch 41 / 100 , loss: tensor(0.0360, grad_fn=<MseLossBackward0>)\n",
      "epoch 42 / 100 , loss: tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "epoch 43 / 100 , loss: tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "epoch 44 / 100 , loss: tensor(0.1759, grad_fn=<MseLossBackward0>)\n",
      "epoch 45 / 100 , loss: tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch 46 / 100 , loss: tensor(0.0763, grad_fn=<MseLossBackward0>)\n",
      "epoch 47 / 100 , loss: tensor(0.1305, grad_fn=<MseLossBackward0>)\n",
      "epoch 48 / 100 , loss: tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch 49 / 100 , loss: tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch 50 / 100 , loss: tensor(0.3658, grad_fn=<MseLossBackward0>)\n",
      "epoch 51 / 100 , loss: tensor(0.1664, grad_fn=<MseLossBackward0>)\n",
      "epoch 52 / 100 , loss: tensor(0.0412, grad_fn=<MseLossBackward0>)\n",
      "epoch 53 / 100 , loss: tensor(0.2414, grad_fn=<MseLossBackward0>)\n",
      "epoch 54 / 100 , loss: tensor(0.4722, grad_fn=<MseLossBackward0>)\n",
      "epoch 55 / 100 , loss: tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "epoch 56 / 100 , loss: tensor(0.0412, grad_fn=<MseLossBackward0>)\n",
      "epoch 57 / 100 , loss: tensor(0.0936, grad_fn=<MseLossBackward0>)\n",
      "epoch 58 / 100 , loss: tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "epoch 59 / 100 , loss: tensor(0.0865, grad_fn=<MseLossBackward0>)\n",
      "epoch 60 / 100 , loss: tensor(0.2716, grad_fn=<MseLossBackward0>)\n",
      "epoch 61 / 100 , loss: tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch 62 / 100 , loss: tensor(0.0395, grad_fn=<MseLossBackward0>)\n",
      "epoch 63 / 100 , loss: tensor(0.0783, grad_fn=<MseLossBackward0>)\n",
      "epoch 64 / 100 , loss: tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "epoch 65 / 100 , loss: tensor(0.1784, grad_fn=<MseLossBackward0>)\n",
      "epoch 66 / 100 , loss: tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch 67 / 100 , loss: tensor(0.1202, grad_fn=<MseLossBackward0>)\n",
      "epoch 68 / 100 , loss: tensor(0.2766, grad_fn=<MseLossBackward0>)\n",
      "epoch 69 / 100 , loss: tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "epoch 70 / 100 , loss: tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch 71 / 100 , loss: tensor(0.1382, grad_fn=<MseLossBackward0>)\n",
      "epoch 72 / 100 , loss: tensor(0.2683, grad_fn=<MseLossBackward0>)\n",
      "epoch 73 / 100 , loss: tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch 74 / 100 , loss: tensor(0.1659, grad_fn=<MseLossBackward0>)\n",
      "epoch 75 / 100 , loss: tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "epoch 76 / 100 , loss: tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch 77 / 100 , loss: tensor(0.1163, grad_fn=<MseLossBackward0>)\n",
      "epoch 78 / 100 , loss: tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch 79 / 100 , loss: tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "epoch 80 / 100 , loss: tensor(0.1996, grad_fn=<MseLossBackward0>)\n",
      "epoch 81 / 100 , loss: tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch 82 / 100 , loss: tensor(0.1156, grad_fn=<MseLossBackward0>)\n",
      "epoch 83 / 100 , loss: tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch 84 / 100 , loss: tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch 85 / 100 , loss: tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch 86 / 100 , loss: tensor(0.1531, grad_fn=<MseLossBackward0>)\n",
      "epoch 87 / 100 , loss: tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "epoch 88 / 100 , loss: tensor(0.1695, grad_fn=<MseLossBackward0>)\n",
      "epoch 89 / 100 , loss: tensor(0.1576, grad_fn=<MseLossBackward0>)\n",
      "epoch 90 / 100 , loss: tensor(0.2056, grad_fn=<MseLossBackward0>)\n",
      "epoch 91 / 100 , loss: tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch 92 / 100 , loss: tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch 93 / 100 , loss: tensor(0.0721, grad_fn=<MseLossBackward0>)\n",
      "epoch 94 / 100 , loss: tensor(0.0556, grad_fn=<MseLossBackward0>)\n",
      "epoch 95 / 100 , loss: tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "epoch 96 / 100 , loss: tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "epoch 97 / 100 , loss: tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch 98 / 100 , loss: tensor(0.3538, grad_fn=<MseLossBackward0>)\n",
      "epoch 99 / 100 , loss: tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch 100 / 100 , loss: tensor(0.0578, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "le_model.train()\n",
    "\n",
    "for name, param in le_model.named_parameters():\n",
    "    if '0' in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "hl_loss_fct = nn.MSELoss()\n",
    "hl_optimizer = Adam(le_model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs_3):\n",
    "    for X_input, y_label in train_loader:\n",
    "\n",
    "        hl_optimizer.zero_grad()\n",
    "        X_pred = le_model(X_input)\n",
    "\n",
    "        hl_loss = hl_loss_fct(X_pred, y_label)\n",
    "        hl_loss.backward()\n",
    "        hl_optimizer.step()\n",
    "\n",
    "    print('epoch', epoch + 1, '/', num_epochs_3, \", loss:\", hl_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2010087\n"
     ]
    }
   ],
   "source": [
    "le_model.eval()\n",
    "\n",
    "mse_eval = 0\n",
    "n_test = len(y_test)\n",
    "with torch.no_grad()\n",
    "    for (X, y_true) in test_loader:\n",
    "    \n",
    "        y_eval = le_model(X)\n",
    "        mse_eval += (y_true - y_eval)**2\n",
    "    \n",
    "    rmse_eval = (mse_eval.detach().numpy()/n_test)**0.5\n",
    "\n",
    "print(rmse_eval[0][0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:05<00:00, 1840.09it/s]\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/test_features.csv').set_index('Id')\n",
    "\n",
    "features_test = df_to_tensor(df_test[df_test.columns[1:]])\n",
    "\n",
    "pred_data = testData(features_test)\n",
    "\n",
    "predloader = DataLoader(pred_data, batch_size=1)\n",
    "print(\"Dataloader created\")\n",
    "prediction = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in tqdm(predloader):\n",
    "\n",
    "        y_predict = le_model(X_batch).squeeze(-1).numpy()[0]\n",
    "\n",
    "        prediction.append(y_predict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "outputs": [],
   "source": [
    "IDs = np.arange(50100, 60100)\n",
    "\n",
    "dict = {'Id': IDs, 'y': prediction}\n",
    "\n",
    "submissions = pd.DataFrame(dict)\n",
    "submissions.to_csv('submissions.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}