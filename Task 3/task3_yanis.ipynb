{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3\n",
    "#### --> New try: CNN new model with Mobile Net\n",
    "Inspired by this tutorial by keras: https://keras.io/examples/vision/siamese_network/\n",
    "\n",
    "Notebook to be run in Google Colab for computational efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import random\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autorize access to files in the Google Drive (needed for the Colab notebook to work)\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the essential constants\n",
    "height = 224\n",
    "width = 224\n",
    "epochs = 5\n",
    "test_size = 59544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the necessary functions for preprocessing, training and evaluation \n",
    "\n",
    "def preprocess_triplet(triplet, train):\n",
    "    #Loading and preprocessing of triplets of images\n",
    "    index = tf.strings.split(triplet)\n",
    "    triplet = []\n",
    "    for k in range(3):\n",
    "        image = tf.io.read_file('drive/My Drive/Colab Notebooks/food/' + index[k] + '.jpg')\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = tf.image.resize(image, (height, width))\n",
    "        image = tf.keras.applications.mobilenet_v3.preprocess_input(image)\n",
    "        triplet.append(image)\n",
    "    if train:\n",
    "        return tf.stack(triplet, axis=0), 1\n",
    "    else:\n",
    "        return tf.stack(triplet, axis=0)\n",
    "\n",
    "def load_data(data, train=True):\n",
    "    data = tf.data.TextLineDataset(data)\n",
    "    data = data.map(lambda triplet: preprocess_triplet(triplet, train), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    return data\n",
    "\n",
    "def compute_distances(outputs):\n",
    "    distance_plus = tf.reduce_sum(tf.square(outputs[..., 0] - outputs[..., 1]), axis=1)\n",
    "    distance_minus = tf.reduce_sum(tf.square(outputs[..., 0] - outputs[..., 2]), axis=1)\n",
    "    return distance_plus, distance_minus\n",
    "\n",
    "def triplet_loss(_, outputs):\n",
    "    distance_plus, distance_minus = compute_distances(outputs)\n",
    "    return tf.reduce_mean(tf.math.softplus(distance_plus - distance_minus))\n",
    "\n",
    "def accuracy(_, outputs):\n",
    "    distance_plus, distance_minus = compute_distances(outputs)\n",
    "    return tf.reduce_mean(tf.cast(tf.greater_equal(distance_minus, distance_plus), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into training and validation sets\n",
    "with open('drive/My Drive/Colab Notebooks/train_triplets.txt', 'r') as file:\n",
    "    triplets = [line for line in file.readlines()]\n",
    "\n",
    "train, val = train_test_split(triplets, test_size=0.2)\n",
    "train_size = len(train)\n",
    "\n",
    "with open('drive/My Drive/Colab Notebooks/train_set.txt', 'w') as file:\n",
    "    for triplet in train:\n",
    "        file.write(triplet)\n",
    "\n",
    "with open('drive/My Drive/Colab Notebooks/val_set.txt', 'w') as file:\n",
    "    for triplet in val:\n",
    "        file.write(triplet)\n",
    "\n",
    "train_dataset = load_data('drive/My Drive/Colab Notebooks/train_set.txt')\n",
    "val_dataset = load_data('drive/My Drive/Colab Notebooks/val_set.txt')\n",
    "test_dataset = load_data('drive/My Drive/Colab Notebooks/test_triplets.txt', train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define architecture of the model using a pretrained model (Large minimalistic MobileNet --> https://keras.io/api/applications/mobilenet/)\n",
    "pretrained_model = tf.keras.applications.MobileNetV3Large(include_top=False, minimalistic=True, input_shape=(height, width, 3))\n",
    "pretrained_model.trainable = False\n",
    "custom_layers = tf.keras.Sequential([\n",
    "                                    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                                    tf.keras.layers.Dropout(0.3),\n",
    "                                    tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=None),\n",
    "                                    tf.keras.layers.Lambda(lambda t: tf.math.l2_normalize(t, axis=1))\n",
    "                                    ])\n",
    "                            \n",
    "inputs = tf.keras.Input(shape=(3, height, width, 3))\n",
    "output_triplet = []\n",
    "for k in range(3):\n",
    "    output_triplet.append(custom_layers(pretrained_model(inputs[:, k, ...])))\n",
    "output = tf.stack(output_triplet, axis=-1)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile and training of the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=triplet_loss, metrics=[accuracy])\n",
    "train_dataset = train_dataset.shuffle(1024, reshuffle_each_iteration=True).repeat().batch(32)\n",
    "val_dataset = val_dataset.batch(32)\n",
    "model.fit(train_dataset, steps_per_epoch=int(train_size/32), epochs=epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of the model and predictions\n",
    "distance_positive, distance_negative = compute_distances(model.output)\n",
    "preds = tf.cast(tf.greater_equal(distance_negative, distance_positive), tf.int8)\n",
    "pred_model = tf.keras.Model(inputs=model.inputs, outputs=preds)\n",
    "\n",
    "test_dataset = test_dataset.batch(64).prefetch(2)\n",
    "preds = pred_model.predict(test_dataset, steps=int(test_size/64), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the predictions in the correct format\n",
    "np.savetxt('drive/My Drive/Colab Notebooks/sub.txt', preds, fmt='%i')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d954cd638a1e7c86344e891e12f64c2dae4614b72a421e6b381622588a12ad0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
